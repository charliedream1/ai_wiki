参考： https://github.com/vllm-project/vllm/issues/3900

Quantized MoE models except for Mixtral (e.g. Deepseek, Qwen-MoE, DBRX) are not supported by vLLM at the moment.