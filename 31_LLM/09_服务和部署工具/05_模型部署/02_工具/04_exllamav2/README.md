Github (3k stars): https://github.com/turboderp/exllamav2
- support quant to various precision, e.g. 6.5 bit, 3 bit
- speed almost the same as vllm