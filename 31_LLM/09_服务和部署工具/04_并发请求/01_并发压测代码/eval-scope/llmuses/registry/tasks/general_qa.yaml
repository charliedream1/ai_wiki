model_args:    # model args should be followed by benchmark requirements
  revision: default
  precision: torch.float16
  device_map: auto
#  model_name_or_path: qwen/qwen-7b-chat
generation_config:
  temperature: 0.3
  max_length: 2048
  max_new_tokens: 512
  top_k: 50
  top_p: 0.85
  do_sample: true
  num_beams: 1
  repetition_penalty: 1.0
#  eos_token_id: null
#  pad_token_id: null
dataset_args: {}
dry_run: false
model: null   # Note: to be implemented as CustomModel
eval_type: custom
datasets:
  - general_qa
outputs: null    # structure: configs, logs, predictions, reviews, reports # TODO: need to parse
use_cache: false
stage: all
dataset_hub: Local    # `Local` or `ModelScope`
limit: null
