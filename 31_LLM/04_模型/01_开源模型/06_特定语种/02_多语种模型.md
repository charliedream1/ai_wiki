开源地址：https://github.com/babel-llm/babel-llm

笑脸：https://huggingface.co/Tower-Babel

Babel一共提供了9B和83B两个版本，9B专为高效的多语言大模型推理和微调设计，适合研究和本地部署；而83B性能更好，但消耗的资源也更多。

Babel的创新之一是其独特的层扩展技术。传统的大模型在提升性能时，通常采用持续预训练的方法，在现有模型的基础上不断增加训练数据量或调整训练策略。但这种方法往往难以突破模型的性能上限，尤其是在面对多语言任务时，模型的复杂性和多样性对性能提出了更高的要求。

为了解决这一难题，Babel采用了层扩展技术，通过在模型中插入额外的层来增加参数数量从而提升模型的性能。



# 参考

[1] 阿里开源多语言大模型，支持全球90%人口, https://mp.weixin.qq.com/s/02bESXWFtk3hUVq4gCpltA