# 1. LLM
## 1.1 入门项目

1. baby-llama2-chinese
    - 用于从头预训练+SFT一个小参数量的中文LLaMa2的仓库；24G单卡即可运行得到一个具备简单中文问答能力的chat-llama2.
    - https://github.com/DLLXW/baby-llama2-chinese
    - 899 stars

## 1.2 模型训练框架


## 1.3 综合训练框架

1. LLaMA-Factory
   - 简介：支持多种不同模型，支持pretrain、sft、ppo、RLHF各流程，较全面
   - https://github.com/hiyouga/LLaMA-Factory
   - 7.6 Stars

2. Firefly
   - 简介：从数据、模型、原理和代码全开源，较好的去学习和复现
   - https://github.com/yangjianxin1/Firefly
   - 3.4k Stars

2. ChatGPT原理与实战：大型语言模型的算法、技术和私有化
   - https://github.com/liucongg/ChatGPTBook
   - 167 Stars
   - 公众号：刘聪NLP 
   - 简介：包含pretrain、sft、ppo、RLHF各流程

## 1.4 MOE

1. Mixtral-8x7B-32K MoE

   Mixtral-8x7B-32K一款混合专家模型（Mixtrue of Experts)，通过将多个专家模型结合在一起，
   获得更好的推理结果。据传GPT4也采用了类似的策略。目前MistralAI官方只发布了模型权重，推理代码尚未发布。
   但是大神无处不在，Github上已经有人搞出了推理代码，但是加载模型需要至少2 x 80Gb 或者 4 x 40Gb 显存。

   - 推理代码：https://github.com/dzhulgakov/llama-mistral
   - Fork 7.9k, Star 109
   - 模型权重：https://huggingface.co/someone13574/mixtral-8x7b-32kseqlen


## 1.5 知识库

1. Langchain-Chatchat
   - https://github.com/chatchat-space/Langchain-Chatchat
   - 17.1k星

# 2. 训推一体化平台

https://www.gitpp.com/unrealdb/projcet0710gvv0901

从模型管理到推理部署，从训练微调到性能评估， 将复杂的AI工作流程简化为直观易用的一体化平台。

核心功能

🎯 模型管理

统一模型仓库
: 支持HuggingFace模型库的无缝集成和本地模型管理
版本控制
: 完整的模型版本管理和追踪功能
元数据管理
: 详细的模型信息、标签和分类管理
🔥 模型推理

高性能推理
: 基于vLLM引擎，提供高效的模型推理服务
实时API
: RESTful API接口，支持多种推理模式
批量处理
: 支持批量推理任务和异步处理
🎓 模型训练

一键微调
: 集成Oumi框架，简化模型训练流程
配置管理
: 灵活的训练配置和参数调优
训练监控
: 实时训练进度监控和日志管理
📊 模型评估

多维度评估
: 支持多种评估指标和基准测试
对比分析
: 模型性能对比和可视化分析
报告生成
: 自动生成详细的评估报告
💬 智能聊天

快捷聊天
: 内置聊天界面，快速体验模型效果
多模型切换
: 支持多个模型间的快速切换
对话历史
: 完整的对话记录和管理


# 参考

[1] 震撼！大模型一体化推训平台 开源！https://mp.weixin.qq.com/s/NhexFqHIqWQxUA8HVk5U8w
