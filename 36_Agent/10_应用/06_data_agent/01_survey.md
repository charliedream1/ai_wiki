参考： https://mp.weixin.qq.com/s/ReTRhA5grL3F5J3r47Fq7Q

数据分析智能体现在发展到什么阶段了？
有什么优秀的方案/技术/竞品可以借鉴吗？
数据处理经验可以迁移到其他企业级Agent产品吗？

今天，我们就通过上海交大、清华、微软研究院等机构的综述论文：《LLM/Agent-as-Data-Analyst: A Survey》，全面了解一下，如何用LLM/Agent把传统数据分析（需要专业技能、手动操作、多工具拼接），变成智能分析（人人能用、自动高效、跨数据类型兼容）。

论文地址：https://arxiv.org/abs/2509.23988

图片
传统数据分析的4个致命痛点
传统数据分析（Excel、SQL、BI）虽能提取信息与统计模式，但随着数据规模与复杂度增长，在业务中依然存在门槛高、效率低、覆盖窄的问题，论文总结为4个核心痛点，每一个都是业务用户和分析师的日常吐槽。

1、封闭世界假设：只能处理单一数据类型。
系统仅适配特定数据类型（如关系数据库处理结构化数据、MongoDB处理JSON），跨模态分析需切换工具和人工对齐，增加复杂度与误差。

2、工具绑定：必须学专业工具。
依赖与系统深度绑定的专用工具（如可视化仪表盘、机器学习库），非技术用户想查数据，必须学SQL、Python或BI的语法，否则只能找分析师帮忙，响应慢。

3、基础字面分析：不懂业务语言。
只能按关键词支持过滤、聚合等表层操作，无法理解数据语义（如文本情感/因果关系，图表需人工解读），分析深度有限。

4、依赖手动开发：新需求无法快速适配。
每次新分析需求，都要分析师手动定流程：选数据源、写查询语句、调模型、画图表，重复劳动多，且无法快速适配新需求。

LLM/Agent数据分析产品的价值
LLM/Agent不是优化工具，而是重构了数据分析的交互方式和工作流，对应解决上述4个痛点，带来4个关键价值：

1、跨模态兼容：一个系统搞定所有数据类型。
LLMs可处理关系数据、半结构化表格、非结构化文本等多模态数据，捕捉潜在模式与上下文依赖。

2、自然语言交互：把技术接口换成业务语言。
以自然语言为核心接口，用户无需掌握 SQL、编程技能即可表达分析意图，降低非专业用户的使用门槛，推动数据驱动决策的普及。

3、语义级理解：系统能懂业务概念。
支持语义聚合、语义过滤、语义连接等高阶操作，突破句法匹配局限。

4、自动工作流：系统自己规划+执行+优化。
Agent可根据用户意图与数据上下文动态选择数据源、操作与工具，构建端到端自主工作流；部分研究探索系统自演进（如自动设计提示词、生成Agent模块）。

不同数据模态的技术应用
论文按数据模态分了4类：结构化数据分析、半结构化数据分析、非结构化数据分析、异构数据分析。

结构化数据分析
这是企业最常用的规范数据，是具有明确定义schema的数据（如关系数据、图数据、时间序列数据），核心是通过LLM实现自然语言交互+语义推理+工作流自动化。

方案核心要点：LLMs通过结构+语义联合建模，实现跨表/图/时间序列的统一理解，自动将自然语言意图转化为可执行查询（SQL/GQL/代码）。

关系数据（MySQL、Oracle）
核心产品功能方向：会话式BI、自动SQL生成。

核心技术方向：

•
自然语言接口（NL2SQL、NL2Code）
•
语义分析（多步QA、端到端QA）
•
数据构建
代表方法/模型：

•
NL2SQL：Spider数据集、Schema Linking、PICARD解码
•
NL2Code：PACHINCO（微调PALM）、Data Interpreter
•
语义QA：TableGPT2（微调Qwen2.5）、TableLLaVA（表格转图像）
图数据（知识图谱、社交网络）
核心产品功能方向：自然语言查关联关系。

核心技术方向：

•
自然语言到图查询（NL2GQL）
•
语义分析（检索推理、执行推理、Agent推理）
代表方法/模型：

•
NL2GQL：R³-NL2GQL（双LLM协作）、NAT-NL2GQL（三Agent框架）
•
语义分析：InstructGraph（DPO对齐）、GraphGPT（结构编码模块）
时间序列数据（服务器负载、销量趋势）
核心产品功能方向：时序转自然语言、自动异常检测。

核心技术方向：

•
TS2NL（时间序列转自然语言）
•
时间序列对齐（编码器设计、LLM微调）
代表方法/模型：

•
TS2NL：TimeCAP（双Agent协作）、TimeXL（三Agent+原型编码器）
•
对齐方法：TIMELLM（补丁重编程）、CALF（跨模态token对齐）
半结构化数据分析
半结构化数据兼具部分规范性与灵活性（如HTML/JSON、中国式报表），核心挑战是处理不规则结构+嵌套关系，LLM技术重点在于结构感知+语义推理。

方案核心要点：LLMs突破传统PLM的结构建模局限，通过结构转换（半结构化→结构化）+语义压缩”处理复杂格式，降低人工干预。

标记语言（XML/JSON/HTML）
核心产品功能方向：自动提取网页/接口数据。

核心任务：标记提取、信息查询、语义理解。

关键技术：

•
提取：Evaporate（LLM生成多候选提取函数）、WebFormer（DOM节点编码+跨注意力）
•
查询：XPath Agent（两阶段生成XPath）、SMART（Text-to-NoSQL，结合SLM+RAG）
•
理解：MarkupLM（XPath嵌入+三预训练任务）、WebLM（多模态预训练，融合结构/文本/视觉）
半结构化表格（合并单元格、层级表头）
核心产品功能方向：自动整理表格格式

核心特征：层级内容、合并单元格、灵活表头、内容不一致。

关键技术：

•
表格表示：TUTA（树状编码）、TabFormer（CoT转换为关系数据）
•
表格提示：SHEETCOMPRESSOR（结构锚点+倒排索引压缩）、HySem（单元格文本压缩）
•
表格查询：CoS（子表定位+LLM 推理）、ST-Raptor（HO-Tree分解查询）
非结构化数据分析
非结构化数据无固定格式，涵盖图表、视频、文档、3D 模型，LLM 技术核心是跨模态融合+ 语义grounding。

方案核心要点：多模态大模型是核心工具，通过模态对齐+Agent编排，实现从视觉感知到语义推理的跨越。

图表（财报图、监控图）
核心产品功能方向：图表问答、自动解读。

核心任务：图表描述、图表QA、图表转代码（Chart-to-Code）、数据合成。

关键技术与代表模型：

•
描述：ChartThinker（CoT策略）、UniChart（预训练多任务）
•
QA：Charts-of-Thought（四步数据处理）、ChartGemma（视觉指令微调）
•
合成：ChartLlama（GPT-4生成三阶段数据）
视频（监控、会议录像）
核心产品功能方向：自动标事件、异常检测。

核心任务：时间定位、情感分析、目标检测、手势行为检测。

关键技术与代表模型：

•
时间定位：TimeMarker（时间分隔符token）、Grounded-VideoLLM（离散时间token）
•
情感分析：PERMA（非语言线索提取）、HARMONI（3D网格重建）
•
效率优化：动态帧采样、token合并
文档（合同、报告）
核心产品功能方向：关键信息提取、问答

核心任务：多模态理解（文本+布局+视觉）、检索问答、文档生成。

关键技术与代表模型：

•
架构：LayoutLM 系列（文本+布局嵌入）、DocLLM（布局感知生成）
•
理解：VisDoM（双分支RAG）、SV-RAG（LoRA微调VLM）
•
生成：PosterLlama（HTML代码生成布局）
3D模型（工业零件、建筑模型）
核心产品功能方向：自然语言查3D属性

核心任务：语言融合、3D衍生任务增强、跨模态精炼。

关键技术与代表模型：

•
融合：3D-LLM（点云转多视图）、3UR-LLM（端到端多模态）
•
领域适配：3D-MoLM（分子）、ProteinChat（蛋白质）
•
生成：CraftsMan3D（3D latent diffusion）、LLaMA-Mesh（LLM输出网格）
异构数据分析
异构数据指多模态数据的融合（如关系数据+文档图像+表格），核心挑战是模态对齐+跨模态推理，LLM 技术聚焦三大方向：

•
模态对齐：将不同模态映射到统一语义空间，如Unicorn（DeBERTa+MoE特征对齐）、Symphony（数据转自然语言摘要后向量编码）
•
异构数据检索：支持跨模态查询，如LOTUS（声明式编程接口）、CAESURA（嵌入VQA模型处理视觉查询）
•
异构数据分析Agent：自动分解查询并跨模态执行，如 XMODE（SQL+VLM协作）、AgenticData（多Agent逻辑计划生成）
方案核心要点：LLMs通过自然语言中介打破模态壁垒，实现异构数据的统一检索与分析，减少人工干预。

现在已有哪些产品在用这些技术？
论文列出了落地案例，帮你对标同行，看看不同数据类型的产品都在做什么。

多数产品仍处于工具辅助阶段，自主设计新型分析工作流的能力（开发自主性）尚未成熟，跨模态推理精度需提升。

结构化数据
Dataiku：统一AI平台，用户输自然语言，自动生成数据预处理、建模、可视化的全流程。

Cognite：工业知识图谱，用自然语言查设备故障历史，自动关联图数据和时序数据，出故障分析报告。

半结构化数据
Tableau：会话式BI，用户输近半年各区域销售额，自动生成可视化图表，支持交互调整。

Parseur：自动解析工具，自动提取邮件、PDF 中的半结构化数据（如订单号、金额），转成规范表格。

非结构化数据
docAnalyzer.ai：文档智能分析，结合布局和文本，自动提取合同、报告中的关键信息，支持问答（如 “合同有效期”）。

viAct：安防视频分析，自动识别监控中的异常行为（如攀爬、斗殴），标时间点并生成告警，不用人工盯屏。

异构数据
Dremio：数据湖查询，自动关联不同数据源（Hadoop、MySQL、文档），用户输自然语言即可跨源查询。

GE Predix：工业IoT分析，关联传感器时序数据和设备维护文档，自动预测设备下次故障时间。

挑战与未来方向
当前技术还没完全成熟，这些待解决的问题就是产品差异化的机会。

结构化数据
复杂分析能力不足：现有LLMs难以处理语义+结构深度融合的多步推理任务，需探索多Agent协作（任务分解+专业化子任务）；

开放世界适配差：域特异性（如金融/医疗表格）与SQL方言差异导致泛化性低，需研究高效自动数据生成与跨方言查询转换。

半结构化数据
标记语言覆盖不全：现有研究聚焦HTML/JSON，JATS/LaTeX 等领域专用格式待探索，需构建专用基准与结构感知模型；

大规模表格理解效率低：LLM上下文窗口限制导致大表格处理需压缩结构/内容，需研究分层编码与增量推理。

非结构化数据
图表高阶理解缺失：缺乏图表事实核查、视觉误导检测能力，需构建含错误标注的数据集与联合视觉-语义推理模型；

视频计算效率低：固定帧采样浪费算力，需研究动态采样与token合并技术，平衡效率与细节保留；

3D模型表示精度低：点云/网格的LLM输入转换易丢失几何细节，需开发紧凑且拓扑保留的编码器。

异构数据
模态扩展性差：新增模态需重新设计系统，需构建模块化框架与自适应模态权重学习；

高阶分析能力弱：现有系统仅支持检索，缺乏跨模态总结与推理，需探索多模态嵌入联合推理与符号-神经融合。

总结
LLM/Agent 技术正在重构数据分析的范式，从人工驱动、封闭工具、字面分析，向自主驱动、开放工具、语义理解演进。

未来研究需围绕跨模态统一建模、自主工作流演进、开放世界适配三大核心，推动技术从实验室验证走向工业级可靠应用，最终实现零代码、全自主的智能数据分析系统。

另外，我认为这些数据分析技术对跨领域的企业级Agent产品也很有参考意义，企业内的数据多种多样、数量庞大，这些都是驱动Agent决策和行动的环境要素，通过合理的方案感知和理解它们，是企业级Agent落地并产生价值的关键。

最后，如果今天的内容对你有价值，别忘了点赞、关注、推荐，你的反馈对我十分重要。