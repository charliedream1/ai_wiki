早先 UC Berkeley 的论文《Why Do Multi-Agent LLM Systems Fail?》（链接：https://arxiv.org/abs/2503.13657）就曾揭示，虽然我们都期望多智能体系统能做到「1 + 1 > 2」的效果，但是实测下来却不尽如人意。构建 Devin 的 Cognition AI 最近在《Don’t Build Multi-Agents》（链接：https://cognition.ai/blog/dont-build-multi-agents）一文中，也对多智能体系统「上下文共享」的困难，以及面临的「过度工程化」表达了担忧，转而更关注提升单智能体的可靠性。

虽然反对声音不绝于耳，但也不乏有力的支持者。Anthropic 在文章《How we built our multi-agent research system》（链接：https://www.anthropic.com/engineering/built-multi-agent-research-system）中认为多智能体系统在处理复杂问题时，就应该用更多的 Token 换取更好的效果这样的「力大砖飞」策略，同时也提出了诸多优化方法，比如并行优化、工具选型、智能体自我改进等。

# 参考

[1] https://mp.weixin.qq.com/s/TKev6oPft5I1VOlXqHwONQ