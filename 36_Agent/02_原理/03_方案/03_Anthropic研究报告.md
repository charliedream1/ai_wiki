举个例子，假设我们有以下一个任务：

“列出 S&P 500 指数中信息技术类公司的所有董事会成员。”

这个任务听起来不算太复杂，但如果你要完成它，需要做这些事：

找到 S&P500 里哪些公司是 IT 类的

确定每个公司的董事会名单

过滤和格式化信息

引用权威来源（官网、年报等）

任何一个人来做，至少也得开十几个网页、抄几段文字、交叉验证几次。

Claude 作为单智能体尝试回答时，始终跳不出线性流程：查一个公司→处理→再查一个。速度慢，信息不全，容易出错。

于是 Anthropic 让 Claude 换了一种工作方式：

主控智能体负责拆解问题

子智能体并行执行每个子任务

最后由主控智能体整合结果 + 调用“引用助手”添加资料来源

结果非常惊人：

多智能体版本的 Claude，完成率比单智能体提升了 90%。

这个转变背后的启示不只是“多智能体更强”，而是：

面对复杂任务，单点智能再强，也比不过一个分工合理、协调良好的团队。

Claude 的做法是：把这个查询交给一个主控智能体，它会主动制定研究策略、拆解子任务，然后调用多个子智能体同时去查找资料，最后再统一整合成带有引用的研究报告。

这，就是多智能体系统的魅力所在：将复杂任务转化为一个可协作、可迭代、可扩展的任务网络。

Anthropic 是怎么“组织”这支虚拟团队的？
Anthropic 使用了一个经典而有效的组织形式

我们不妨把 Anthropic 的这套系统当作一支团队，来看看他们的组织架构：

1. 角色划分
主控智能体（LeadResearcher）：负责制定策略、明确子任务边界，比如“请查找 A 公司近三年董事变动情况，只使用官网或年报”

子智能体（Subagent）：每个子体接到一个具体小任务后，会自己去用搜索工具查找信息、判断真伪、做出初步总结
→ 关键在于提示词会明确告诉它：“你要输出格式是什么”、“最多搜索几次”、“优先用哪个工具”

引用助手（CitationAgent）：最后接手的是“引用检查员”，它会看所有报告结果，把涉及的内容和原始链接对应起来

记忆系统（Memory）：当任务步骤太多、token 接近上限时，主控智能体会把中间计划写入 memory，等下一轮再调用回来继续任务

工具集：每个智能体都会有一份“工具使用指南”，明确告诉它什么任务用什么工具，比如：“你查 Slack 里的对话内容只能用 A 工具，不要用 Web 搜索”

2. 工作方式并不是线性的，而是并行的
系统不再是“查完一个问题再查下一个”，而是同时创建多个子智能体，各自查找不同的部分，再把结果汇总。

这种方式带来的两个好处是：

速度极快：不需要一个个查完再等结果，所有路径一起探索

结果更全面：每个子智能体有自己独立的关注点，不会遗漏或重复

而主控智能体会判断是否继续深入，比如当一个结果太模糊时，它会“临时再派一名智能体”去补充说明。

提示词工程：让 AI 懂得协作的艺术
没有模板式的流程，而是“策略型提示词”引导
很多人以为 Anthropic 是在堆“提示词模板”。其实他们做的是另一件事：

他们研究了“优秀的人是怎么做研究的”，然后把这些策略变成提示词结构。

教会了智能体一些「团队协作的基本常识」：

不能重复别人做的任务：每个子智能体都被赋予任务 ID，提示词会告诉它“你只负责 XX，不要查别的”

判断自己是否查到了有用信息：如果查到的内容太少、质量不好，它会选择再次搜索或报告失败，而不是胡乱输出

懂得做取舍：每个任务都有一个“搜索预算”（比如最多 10 次），防止死循环

先泛后专：主控智能体会优先引导子体提出“通用关键词”搜索，找到大概信息后，再进一步缩小搜索范围

Anthropic 提到，他们甚至让 Claude 自己检查自己的失败案例，自己来改写提示词和工具描述，从而提升效率。这其实就是用 AI 改善 AI 的使用体验。

比如：“这个工具描述不清，我误以为它能查网页，但其实只能查内部聊天记录”，然后它会写出更清晰的版本。

多智能体系统的性能，70% 取决于提示词设计。

Anthropic 总结了 8 条提示词设计原则，值得所有 Agent 系统参考：

像智能体一样思考：把自己当作 LLM，从它的角度验证 prompt 会如何误解。

教会主控智能体如何分工：为每个子任务提供输出格式、目标、使用工具、边界约束。

任务复杂度 = 资源预算：为简单任务控制工具调用数，为复杂任务合理扩容。

设计工具就像设计 UI：不只是接口，而是要明确用法、适用场景、互斥条件。

让智能体自我提示词调优：Claude 4 能自行优化 prompt 和工具描述，自动缩短任务路径。

搜索策略：先广后深：防止一上来就发长串复杂搜索词导致搜索失败。

显式引导思考过程：使用思维模式输出结构，提升稳定性。

全流程并行执行：3-5 个子智能体并行 + 每个子体多工具并行，大幅加速任务完成速度。

这些原则背后不是“模板”，而是一整套 研究性认知流程的压缩模型。

技术背后的另一面：
这些“工程细节”决定了系统能不能上线
很多“AI 系统”都卡在 demo 阶段，是因为缺乏对复杂性处理的能力。

Anthropic 做了几个关键设计，让这套系统真正能上线使用：

智能体崩溃不等于任务失败：如果一个子智能体出错，系统会中断恢复，而不是整组任务报废

升级版本用“彩虹部署”：确保已有任务不受影响，逐步迁移新版本

任务之间不能互相干扰：每个子任务的上下文和行为被隔离管理

不会记录用户私密信息，但保留系统决策轨迹：方便追踪智能体行为，但不触碰隐私

他们还提到：这类系统“烧 token 烧得很快”，一个多智能体任务可能消耗普通聊天任务 15 倍以上的资源。

所以，这类系统必须应用在“足够有价值的任务”中，比如投资研究、医学方案分析、商业信息搜集等。

所以，这个系统到底适合干嘛？
目前，这套系统主要用在几类任务中：

商业研究 / 投资分析：企业画像、投融资追踪、竞争对手拆解等

信息验证 / 合规查证：比如人物背景调查、文献追踪、事实校验

辅助写作 / 内容策划：比如长篇内容生成、查找引用文献、构建信息大纲

Anthropic 给的数据中，最常见的使用场景是“为复杂领域构建系统化知识材料”，比如为某个医疗话题写背景研究、为某个技术方向整理论文脉络。

一句话总结：如果你问的问题“不是一句话能回答的”，它就很可能适合多智能体系统来完成。

Claude Research 系统的实际价值反馈
Anthropic 收集的用户数据中，有 5 类场景使用最频繁：

专业内容撰写与优化

市场调研与增长策略

学术研究支持

软件系统架构建议

多平台信息验证与交叉比对

部分用户甚至表示：这类 AI 研究系统帮他们节省了“本该花上几天的工作”。

写在最后
AI 模型已经很强大了，但人类解决复杂问题，从来不是靠一个“最聪明的大脑”，而是靠一个分工协作的组织系统。

Anthropic 做的事，归根到底不是做出更强的 Claude，而是：

他们在用“组织行为学”的方式来重塑 AI 的使用范式。

不是让一个模型做一切，而是让多个模型“像人一样工作”：有分工、有节奏、有边界、有策略、有反馈。

这比模型本身的升级更有启发性。

如果我们把 AI 看成“合作者”而非“回答机器”，或许真正的 AI 工作方式，并不是 prompt → 输出，而是：

目标 → 拆解 → 组织 → 调度 → 输出 → 归因

这，不就是我们人类解决问题的方式吗？



# 参考

[1] Anthropic研究报告：揭秘 Claude 深度研究背后的秘密 教你如何构建多智能体研究系统, https://mp.weixin.qq.com/s/IwNFcxJ0oNzreTv5ertIJg