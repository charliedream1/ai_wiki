# 1. 不支持function call的模型

代码来源：langchain neo4j llm graph builder

```python
examples = [
    {
        "text": (
            "亚当自2009年以来一直在微软担任软件工程师，去年他获得了“最佳人才”奖。"
        ),
        "head": "亚当",
        "head_type": "人物",
        "relation": "就职",
        "tail": "微软",
        "tail_type": "公司",
    },
    {
        "text": (
            "亚当自2009年以来一直在微软担任软件工程师，去年他获得了“最佳人才”奖。"
        ),
        "head": "亚当",
        "head_type": "亚当",
        "relation": "获得",
        "tail": "最佳人才",
        "tail_type": "奖励",
    },
    {
        "text": (
            "微软是一家科技公司，提供多种产品，如Microsoft Word。"
        ),
        "head": "Microsoft Word",
        "head_type": "产品",
        "relation": "由...生产",
        "tail": "微软",
        "tail_type": "公司",
    },
    {
        "text": "Microsoft Word 是一个可离线访问的轻量级应用程序",
        "head": "Microsoft Word",
        "head_type": "产品",
        "relation": "具有特征",
        "tail": "轻量级应用程序",
        "tail_type": "特征",
    },
    {
        "text": "Microsoft Word 是一个可离线访问的轻量级应用程序",
        "head": "Microsoft Word",
        "head_type": "产品",
        "relation": "具有特征",
        "tail": "可离线访问",
        "tail_type": "特征",
    },
]

from langchain_core.pydantic_v1 import BaseModel, Field, create_model

class UnstructuredRelation(BaseModel):
    head: str = Field(
        description=(
            "提取出的头实体，如微软、苹果、约翰。"
            "必须使用人类可读的唯一标识符。"
        )
    )
    head_type: str = Field(
        description="提取出的头实体类型，如人物、公司等。"
    )
    relation: str = Field(description="头实体和尾实体之间的关系。")
    tail: str = Field(
        description=(
            "提取出的尾实体，如Microsoft、Apple、John。必须使用人类可读的唯一标识符。"
        )
    )
    tail_type: str = Field(
        description="提取出的尾实体类型，如人物、公司等。"
    )

from langchain_core.messages import SystemMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    PromptTemplate,
)
from typing import Any, Dict, List, Optional, Sequence, Tuple, Type, Union, cast


def create_unstructured_prompt(
    node_labels: Optional[List[str]] = None, rel_types: Optional[List[str]] = None
) -> ChatPromptTemplate:
    node_labels_str = str(node_labels) if node_labels else ""
    rel_types_str = str(rel_types) if rel_types else ""
    base_string_parts = [
        "你是一个顶级算法，旨在以结构化的格式提取信息以构建知识图谱。你的任务是根"
        "据用户提示，从给定文本中识别实体和关系。你必须生成包含JSON对象列表的JSON格式输出。每个对象应包含以下"
        '键："head"、"head_type"、"relation"、"tail"和"tail_type"。"head"键必须包含'
        "从提供的用户提示列表中提取的实体文本，"
        '"head_type"键必须包含提取的头实体的类型。'
        f"必须是{node_labels_str}中的一种类型。"
        if node_labels
        else "",
        f'“relation”键必须包含“head”和“tail”之间关系的类型，必须是{rel_types_str}中的一种关系。'
        if rel_types
        else "",
        f'“tail”键必须表示提取实体的文本，该实体是关系的尾部；“tail_type”键必须包含来'
        f'自{node_labels_str}的尾实体类型。'
        if node_labels
        else "",
        "尽量提取尽可能多的实体和关系。保持实体一致性：在提取实体时，确保一致性。"
        "如果一个实体（例如“约翰·多伊”）在文本中多次提到但使用不同的名字或代词（如"
        '“多伊”、“他”），始终使用该实体的最完整标识符。知识图谱应当连贯且易于理解，'
        "因此保持实体引用的一致性至关重要。",
        "重要提示:\n- 不要添加任何解释和文本。",
    ]
    system_prompt = "\n".join(filter(None, base_string_parts))

    system_message = SystemMessage(content=system_prompt)
    parser = JsonOutputParser(pydantic_object=UnstructuredRelation)

    human_string_parts = [
        "根据以下示例，从提供的文本中提取实体和关系。\n\n"
        "使用以下实体类型，不要使用下面未定义的其他实体类型："
        "# 实体类型:"
        "{node_labels}"
        if node_labels
        else "",
        "使用以下关系类型，不要使用下面未定义的其他关系类型："
        "# 关系类型："
        "{rel_types}"
        if rel_types
        else "",
        "以下是一些文本及其提取的实体和关系示例。"
        "{examples}\n"
        "对于以下文本，请按照提供的示例提取实体和关系。"
        "{format_instructions}\n文本: {input}",
    ]
    human_prompt_string = "\n".join(filter(None, human_string_parts))
    human_prompt = PromptTemplate(
        template=human_prompt_string,
        input_variables=["input"],
        partial_variables={
            "format_instructions": parser.get_format_instructions(),
            "node_labels": node_labels,
            "rel_types": rel_types,
            "examples": examples,
        },
    )

    human_message_prompt = HumanMessagePromptTemplate(prompt=human_prompt)

    chat_prompt = ChatPromptTemplate.from_messages(
        [system_message, human_message_prompt]
    )
    return chat_prompt


from langchain_openai import ChatOpenAI
import json_repair  # type: ignore

allowed_nodes, allowed_relationships = '', ''
prompt = create_unstructured_prompt(
    allowed_nodes, allowed_relationships
)
llm = ChatOpenAI(model="gpt-3.5-turbo-0125", temperature=0)
chain = prompt | llm


raw_schema = chain.invoke({"input": text}, config=config)
parsed_json = json_repair.loads(raw_schema)
```