```python
from langchain_community.chat_models import ChatOllama

from langchain.prompts import PromptTemplate
import re

llm = ChatOllama(base_url='http://localhost:11434', model='qwen2:7b-instruct')

def get_query_gen_chain(n_sim_queries):
    prompt = PromptTemplate(
        input_variables=['question', 'n_sim_queries'],
        template = """你是一个AI语言模型助手。你的任务是基于给定的原始问题，再生成出来最相似的{n_sim_queries}个不同的版本。\
    你的目标是通过生成用户问题不同视角的版本，帮助用户克服基于距离做相似性查找的局限性。\
    使用换行符来提供这些不同的问题，使用换行符来切分不同的问题，不要包含数字序号，仅返回结果即可，不要添加任何其他描述性文本。
    原始问题：{question}
    """
    )
    queries_gen_chain = (
        prompt.partial(n_sim_queries=n_sim_queries)
        | llm
        # 有时候模型不遵循指令，把前面的序号、- 去掉
        | (lambda x: [
            re.sub(r'(^\-\s+)|(^\d+\.\s)', '', item.strip()) 
            for item in x.content.split('\n') if item.strip() != ''
        ])
    )
    return queries_gen_chain


```