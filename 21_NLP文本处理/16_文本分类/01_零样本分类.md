# 1. Political DEBATE

- 论文：Political DEBATE: Efficient Zero-shot and Few-shot Classifiers for Political Text
  - https://arxiv.org/pdf/2409.02078
  - 普林斯顿大学（美国）， 2024.09.03
- 数据及模型：https://huggingface.co/mlburnham
  - 数据：200,000文章，800个分类标签
- 参考代码：https://github.com/MoritzLaurer/zeroshot-classifier
  - 本文为开源代码，此代码为本文所引用的
  - 对应论文：Building Efficient Universal Classifiers with Natural Language Inference
    - https://arxiv.org/pdf/2312.17543

# 2. zeroshot-classifier

- Github (126 stars): https://github.com/MoritzLaurer/zeroshot-classifier
- 对应论文：Building Efficient Universal Classifiers with Natural Language Inference
  - https://arxiv.org/pdf/2312.17543

# 3. Qwen3-0.6B

## 3.1 简介

参考：Qwen3-0.6B能击败Bert吗？https://mp.weixin.qq.com/s/6ilPWbeu7QN27RxF3PKi6A

数据集配置：fancyzhx/ag_news，分类数为 4，分别为 World（0）、Sports（1）、Business（2）、Sci/Tech（3）。训练样本数 120000，测试样本数 7600，样本数量绝对均衡。

使用 Qwen3 训练文本分类模型有 2 种方法：
- 第 1 种是修改模型架构，将模型最后一层替换为输出维度为分类数的线性层。
- 第 2 种是构造 Prompt，以选择题的方式创建问答对，然后进行 SFT 训练。

SFT分类提示词：

```python
prompt = """Please read the following news article and determine its category from the options below.
Article:
{news_article}
Question: What is the most appropriate category for this news article?
A. World
B. Sports
C. Business
D. Science/Technology
Answer:/no_think"""
answer = "<think>\n\n</think>\n\n{answer_text}"
```

news_article 为新闻文本，answer_text 表示标签。

因为 Qwen3 为混合推理模型，所以对非推理问答对要在模板最后加上 /no_think 标识符（以避免失去推理能力），并且回答要在前面加上 <think>\n\n</think>\n\n。

按照 LLama Factory SFT 训练数据的格式要求组织数据，如：

```json
{
  'instruction': "Please read the following news article and determine its category from the options below.\n\nArticle:\nWall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n\nQuestion: What is the most appropriate category for this news article?\nA. World\nB. Sports\nC. Business\nD. Science/Technology\n\nAnswer:/no_think",
  'output': '<think>\n\n</think>\n\nC'
}
```

## 3.2 结论

在 Ag_new 数据集上，各模型效果：Qwen3-0.6B（线性层分类）> Bert > Qwen3-0.6B（SFT 分类）> Qwen3-0.6B（Think Zero-Shot）> Qwen3-0.6B（No Think Zero-Shot）。

各模型训练推理耗时： Qwen3-0.6B（SFT 分类）> Bert > Qwen3-0.6B（线性层分类）。

各模型 RPS：Bert > Qwen3-0.6B（线性层分类） > Qwen3-0.6B（SFT 分类）。

Think 模式下的 Qwen3-0.6B 比 No Think 模式下的 Qwen3-0.6B 准确率仅高出 1%，推理时间比 No Think 慢 20 倍（HF 推理引擎，Batch 推理）。

在训练 Qwen3-0.6B（线性层分类）时，Loss 在前期有点抖动，或许微调一下学习率预热比率会对最终结果有微弱正向效果。

## 3.3 实验局限性

未实验在 Think 模式下 Qwen3-0.6B 的效果（使用 GRPO 直接训练 0.6B 的模型估计是不太行的，可能还是先使用较大的模型蒸馏出 Think 数据，然后再进行 SFT。

或者先拿出一部分数据做 SFT，然后再进行 GRPO 训练（冷启动））。

未考虑到长序列文本如 token 数（以 Bert Tokenizer 为标准）超过 1024 的文本。

也许因为 AgNews 分类任务比较简单，其实不管是 Bert 还是 Qwen3-0.6B 在 F1 超过 0.94 的情况下，都是可用的状态。

Bert（F1：0.945）和 Qwen3-0.6B 线性层分类（F1：0.949）的差距并不明显。如果大家有更好的开源数据集可以用于测试，也欢迎提出。

未测试两模型在中文文本分类任务中的表现。
