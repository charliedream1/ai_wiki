# 1. ç®€ä»‹

1. å¯¹è¯è®°å¿†åŠŸèƒ½ï¼š è¯¥ç³»ç»Ÿèƒ½å¤Ÿè®°å¿†å’Œè¿½è¸ªç”¨æˆ·å’ŒèŠå¤©æœºå™¨äººä¹‹é—´çš„å¯¹è¯å†å²ã€‚è¿™ä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿåœ¨å¯¹è¯ä¸­éšæ—¶å›é¡¾ä¹‹å‰çš„äº¤æµå†…å®¹ï¼Œä»è€Œå®ç°æ›´è¿è´¯çš„å¯¹è¯å’Œæ›´å¥½çš„äº¤äº’ä½“éªŒã€‚

2. å¤šè¯­éŸ³æ¨¡å‹åˆ‡æ¢ï¼š è¯¥ç³»ç»Ÿæ”¯æŒå¤šç§è¯­éŸ³æ¨¡å‹çš„åˆ‡æ¢ã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ä¸åŒçš„è¯­éŸ³æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚è¿™ç§å¤šè¯­éŸ³æ¨¡å‹åˆ‡æ¢åŠŸèƒ½ä½¿å¾—ç³»ç»Ÿåœ¨ä¸åŒè¯­å¢ƒä¸‹æœ‰æ›´å¼ºçš„é€‚ç”¨æ€§å’Œçµæ´»æ€§ã€‚

# 2. ä»£ç 

```python
import os
os.system('pip install dashscope')
os.system('pip install modelscope')
import gradio as gr
from http import HTTPStatus
import dashscope
from dashscope import Generation
from dashscope.api_entities.dashscope_response import Role
from typing import List, Optional, Tuple, Dict
from urllib.error import HTTPError
import wenet
from modelscope.outputs import OutputKeys
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks



default_system = 'You are a helpful assistant.'
chs_model = wenet.load_model('chinese')
YOUR_API_TOKEN = os.getenv('YOUR_API_TOKEN')
dashscope.api_key = YOUR_API_TOKEN
History = List[Tuple[str, str]]
Messages = List[Dict[str, str]]



# åŠ è½½å››ä¸ªä¸åŒçš„è¯­éŸ³åˆæˆæ¨¡å‹
sambert_hifigan_zh_model_id = 'damo/speech_sambert-hifigan_tts_zh-cn_16k'
sambert_hifigan_zh = pipeline(task=Tasks.text_to_speech, model=sambert_hifigan_zh_model_id)

sambert_hifigan_ch_model_id = 'speech_tts/speech_sambert-hifigan_tts_chuangirl_Sichuan_16k'
sambert_hifigan_ch = pipeline(task=Tasks.text_to_speech, model=sambert_hifigan_ch_model_id)

sambert_hifigan_ca_model_id = 'speech_tts/speech_sambert-hifigan_tts_jiajia_Cantonese_16k'
sambert_hifigan_ca = pipeline(task=Tasks.text_to_speech, model=sambert_hifigan_ca_model_id)

sambert_hifigan_ws_model_id = 'speech_tts/speech_sambert-hifigan_tts_xiaoda_WuuShanghai_16k'
sambert_hifigan_ws = pipeline(task=Tasks.text_to_speech, model=sambert_hifigan_ws_model_id)

    
def clear_session() -> History:
    return []

def modify_system_session(system: str) -> str:
    if system is None or len(system) == 0:
        system = default_system
    return system, system, []

def history_to_messages(history: History, system: str) -> Messages:
    messages = [{'role': Role.SYSTEM, 'content': system}]
    for h in history:
        messages.append({'role': Role.USER, 'content': h[0]})
        messages.append({'role': Role.ASSISTANT, 'content': h[1]})
    return messages


def messages_to_history(messages: Messages) -> Tuple[str, History]:
    assert messages[0]['role'] == Role.SYSTEM
    system = messages[0]['content']
    history = []
    for q, r in zip(messages[1::2], messages[2::2]):
        history.append([q['content'], r['content']])
    return system, history

def model_chat(path:str, history: Optional[History], system: str,model:str,voice:str
) -> Tuple[str, str, History]:
    if path is not None:
        query = chs_model.transcribe(path)['text']
        if query is None:
            query = ''
        if history is None:
            history = []
        messages = history_to_messages(history, system)
        messages.append({'role': Role.USER, 'content': query})
        gen = Generation.call(
            model = "qwen-72b-chat",
            messages=messages,
            result_format='message',
            stream=True
        )
        for response in gen:
            if response.status_code == HTTPStatus.OK:
                role = response.output.choices[0].message.role
                response = response.output.choices[0].message.content
                system, history = messages_to_history(messages + [{'role': role, 'content': response}])
            else:
                raise HTTPError('Request id: %s, Status code: %s, error code: %s, error message: %s' % (
                    response.request_id, response.status_code,
                    response.code, response.message
                ))

        output=None
         # è¿›è¡Œè¯­éŸ³åˆæˆ
        sambert_hifigan_tts_model = {
            'é»˜è®¤': sambert_hifigan_zh,
            'å››å·è¯': sambert_hifigan_ch,
            'ç²¤è¯­': sambert_hifigan_ca,
            'ä¸Šæµ·è¯': sambert_hifigan_ws
        }

        # ä½¿ç”¨å¯¹åº”çš„è¯­éŸ³åˆæˆæ¨¡å‹è¿›è¡Œåˆæˆ
        sambert_hifigan_tts = sambert_hifigan_tts_model.get(model)
        
        if model == 'é»˜è®¤':
            output = sambert_hifigan_tts(input=response, voice=voice)
        else:
            output = sambert_hifigan_tts(input=response)
        
        wav = output[OutputKeys.OUTPUT_WAV]
        path = 'output.wav'
        with open(path, 'wb') as f:
            f.write(wav)
        return history, system, path

def update_dropdowns(model,voice):   
    if model == "é»˜è®¤":  
        voice=gr.Dropdown(choices=['zhitian_emo', 'zhiyan_emo', 'zhizhe_emo', 'zhibei_emo'], value='zhitian_emo',label="å£°éŸ³",visible=True) 
    else: 
        voice=gr.Dropdown(choices=['zhitian_emo', 'zhiyan_emo', 'zhizhe_emo', 'zhibei_emo'], value='zhitian_emo',label="å£°éŸ³",visible=False)
    return voice
with gr.Blocks() as demo:
    gr.Markdown("""<p align="center"><img src="https://modelscope.cn/api/v1/models/qwen/Qwen-VL-Chat/repo?Revision=master&FilePath=assets/logo.jpg&View=true" style="height: 80px"/><p>""")
    gr.Markdown("""<center><font size=4>WeNetè¯­éŸ³è¯†åˆ«+Qwen-72B-Chat BotğŸ‘¾+Sambert-Hifiganè¯­éŸ³åˆæˆ</center>""")

    textbox = gr.Microphone(type="filepath",label='å½•éŸ³')
    with gr.Row():
        with gr.Column(scale=3):
            system_input = gr.Textbox(value=default_system, lines=1, label='System', visible=False)
        with gr.Column(scale=1):
            modify_system = gr.Button("ğŸ› ï¸ è®¾ç½®systemå¹¶æ¸…é™¤å†å²å¯¹è¯", scale=2, visible=False)
        system_state = gr.Textbox(value=default_system, visible=False)
    chatbot = gr.Chatbot(label='Qwen-72B-Chat', visible=False)
    model=gr.Dropdown(choices=['é»˜è®¤', 'å››å·è¯', 'ç²¤è¯­', 'ä¸Šæµ·è¯'], value='é»˜è®¤',label="å£°éŸ³æ¨¡å‹")
    voice = gr.Dropdown(choices=['zhitian_emo', 'zhiyan_emo', 'zhizhe_emo', 'zhibei_emo'], value='zhitian_emo',label="å£°éŸ³")
    
    audio_output = gr.Audio(type="filepath",label='è¾“å‡ºéŸ³é¢‘',autoPlay=True)

    with gr.Row():
        clear_history = gr.Button("ğŸ² æ¸…é™¤è®°å¿†")
        sumbit = gr.Button("ğŸš€ å‘é€")

    model.change(update_dropdowns,inputs=[model,voice],outputs=[voice])

    sumbit.click(model_chat,
                 inputs=[textbox, chatbot, system_state,model,voice],
                 outputs=[chatbot, system_input,audio_output],
                 concurrency_limit=10)
    clear_history.click(fn=clear_session,
                        inputs=[],
                        outputs=[chatbot],
                        concurrency_limit=10)
    modify_system.click(fn=modify_system_session,
                        inputs=[system_input],
                        outputs=[system_state, system_input, chatbot],
                        concurrency_limit=10)
demo.queue(api_open=False).launch(height=800, share=False)
```

# å‚è€ƒ

[1] WeNetè¯­éŸ³è¯†åˆ«+Qwen-72B-Chat Bot+Sambert-Hifiganè¯­éŸ³åˆæˆï¼Œhttps://blog.csdn.net/qq_37655607/article/details/135337617