**注意：如下答案来自GPT4o，人工审核基本没有问题，公式未详细审核**

---

BM25（**Best Matching 25**）是信息检索中的一种经典算法，用于根据文档与查询的相关性进行排名。它基于概率检索模型，综合考虑了**词频**、**文档长度**、**逆文档频率**等因素，是 TF-IDF 的一种改进。

### 通俗理解 BM25 的原理

假设你在图书馆找一本关于“人工智能”的书。BM25 就是帮你判断哪本书和“人工智能”最相关的算法。它通过以下几个关键点计算相关性：

---

#### 1. **词的重要性：词越频繁越重要，但不是越多越好**  
   - 如果一个词（如“智能”）在某篇文章中多次出现，那么这篇文章可能和你的查询更相关。
   - 但是，如果一个词出现得过多（如 1000 次），可能是这篇文章太“啰嗦”，相关性不会线性增长。

   BM25 使用一个**饱和函数**来限制词频的影响，公式为：
   \[
   \text{TF}_i = \frac{f(q_i, d)}{f(q_i, d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{\text{avgdl}})}
   \]
   - \( f(q_i, d) \)：词 \( q_i \) 在文档 \( d \) 中出现的次数（词频）。
   - \( |d| \)：文档的长度（词数）。
   - \( \text{avgdl} \)：语料库中文档的平均长度。
   - \( k_1 \)：调节词频对分数影响的参数，通常在 1.2～2.0 之间。
   - \( b \)：控制文档长度对分数影响的参数，范围是 0～1。

---

#### 2. **词的区分能力：稀有词更重要**  
   - 如果某个词（如“人工”）在很多文档中都出现，它的重要性就不高，因为这个词对区分文档相关性没什么帮助。
   - 相反，如果一个词（如“深度学习”）只在少数文档中出现，它就很重要，能更好区分相关性。

   BM25 用**逆文档频率（IDF）**来衡量词的重要性：
   \[
   \text{IDF}_i = \log\left(\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5} + 1\right)
   \]
   - \( N \)：语料库中的总文档数。
   - \( n(q_i) \)：包含词 \( q_i \) 的文档数。

---

#### 3. **文档长度的影响：短文档更集中，长文档更分散**  
   - 一篇短文档如果出现了“人工智能”，说明这篇文档和“人工智能”可能高度相关。
   - 一篇长文档中可能提到了“人工智能”，但它提到的内容很杂，相关性就没那么强。

   BM25 通过**文档长度归一化**（由参数 \( b \) 控制）来平衡短文档和长文档的得分。

---

### BM25 的完整公式
将以上因素结合起来，BM25 的分数计算公式为：
\[
\text{Score}(q, d) = \sum_{i=1}^{|q|} \text{IDF}_i \cdot \frac{f(q_i, d) \cdot (k_1 + 1)}{f(q_i, d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{\text{avgdl}})}
\]
- \( q \)：查询词集合。
- \( d \)：文档。
- \( \text{Score}(q, d) \)：查询 \( q \) 和文档 \( d \) 的相关性分数。

---

### 举例说明
假设你搜索“人工智能”，有两个文档：
1. 短文档 A：**“人工智能正在改变世界。”**
2. 长文档 B：**“人工智能是技术的分支之一。人工智能包括机器学习、深度学习等技术。”**

- **词频（TF）**：文档 B 出现了更多的“人工智能”。
- **文档长度**：文档 A 较短，内容更集中，分数更高。
- **逆文档频率（IDF）**：如果“人工智能”是一个常见词，它的权重会降低。

经过计算，BM25 会综合这些因素，判断文档 A 可能更相关。

---

### 总结 BM25 的优点
1. **综合考虑词频和文档长度**：避免了简单 TF-IDF 的不足。
2. **可调节参数**：通过 \( k_1 \) 和 \( b \) 微调适应不同的场景。
3. **有效性强**：即使在大规模语料库上，BM25 的性能也非常优秀。

BM25 是信息检索领域的一个经典模型，结合 embedding 方法还能进一步提升效果！