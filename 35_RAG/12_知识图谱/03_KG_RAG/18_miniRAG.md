# 1. 资源

- Github (401 star): https://github.com/HKUDS/MiniRAG
- 论文：
  - MiniRAG: Making RAG Simpler with Small and Free Language Models
  - https://arxiv.org/abs/2501.06713
- 数据：
  - LiHua-World Dataset：https://github.com/HKUDS/MiniRAG/blob/main/dataset/LiHua-World/README.md
  - 主要针对端侧日常指令操作场景
- 开发团队：
  - 香港大学数据科学实验室（HKUDS）开发
  - 曾开发：lightRAG, nano-RAG
  - 本代码主要基于lightRAG和nano-RAG的工作

# 2. 要点速览

**论文目的：**
- 使用场景：端侧日常指令操作场景，相对比较简单
- 目的：意在构建一个简化高性能的RAG模型

**MiniRAG核心要点：**
- 提升端侧小模型RAG性能
- 利用轻量级GraphRAG提升性能
- 小模型不擅长总结理解，但可以进行信息抽取
- 效果：该框架在存储空间仅为大型语言模型（LLM）方法的25%的情况下，仍能实现相当的性能

**实用性评价：**
- 对于在云侧有更多资源下，不必要尝试这个方法，可以使用其它更高级的GraphRAG方案

**核心原理：**
- 一种语义感知的异构图索引机制，将文本块和命名实体结合在一个统一结构中，减少了对复杂语义理解的依赖；
- 一种轻量级的拓扑增强检索方法，利用图结构实现高效的知识发现，而无需高级语言能力。

**效果：**   
该框架在存储空间仅为大型语言模型（LLM）方法的25%的情况下，仍能实现相当的性能

**主要设计思路基于对小型语言模型的三个关键发现：**
- 虽然在复杂语义理解上存在局限，但在模式匹配和局部文本处理方面表现优异
- 通过引入显式结构信息，可有效弥补有限的语义理解能力
- 将复杂RAG任务分解为简单明确的子任务，可在不依赖高级推理能力的情况下保持系统稳定性

**开源资源：**
- 源代码
- 数据集LiHua-World，用于评估轻量级RAG系统在现实设备场景下处理复杂查询的能力

![](.18_miniRAG_images/工作流.png)

MiniRAG 采用基于两个关键组件构建的精简工作流程:异构图索引和轻量级的基于图的知识检索。这种架构解决了设备端 RAG 系统面临的独特挑战,在效率和效果之间实现了优化。

# 3. 原理简介

**语义感知异构图索引**

该机制通过系统性地整合文本块和命名实体，构建了一个富有层次的语义网络，实现高效精准的信息检索。

- 实体节点：包含从文本中提取的重要语义元素，例如事件、地点、时间以及特定领域的相关概念。
- 文本块节点：用于保留原始文本的完整上下文信息，确保文本的连贯性。

通过这种双层节点结构，文本块可以在检索过程中直接参与匹配，显著提高检索结果的相关性和准确性。此外，该方法还巧妙地弥补了小型语言模型在文本摘要能力上的不足，尽可能地减少了信息失真。

**轻量级知识检索**

检索方式：包含2个核心设计，结合语义感知异构图和轻量级文本嵌入，实现高效精准的知识获取。

- 查询语义映射：通过简化的查询解析流程，将用户查询高效映射到图索引结构中。
  - 实体抽取（问题分解等方法小模型性能较差，所以不采用）
  - 根据相似度匹配：实体-实体，实体-文本块，问题-实体
- 拓扑增强检索：采用两阶段检索策略
  - 一阶段：基于嵌入相似度确定初始种子实体
    - 计算相关节点周围的节点，挑选k步以内的连接点，按照重要性公式挑选top-k节点
  - 二阶段：再利用异构图的拓扑结构，沿着相关推理路径发现更多相关信息。

# 4.数据集介绍

![](.18_miniRAG_images/lihua_world数据集.png)

LiHua-World 是一个专门为本地 RAG 场景设计的数据集，包含了一个名为 LiHua 的虚拟用户一年内的聊天记录。该数据集包含三种类型的问题：单跳、多跳和总结性问题，每个问题都配有人工标注的答案和支持文档。更多细节请参考 LiHua-World 数据集的 README。

覆盖方向：
- 社交互动  
- 健身训练  
- 娱乐活动  
- 生活事务
- ...

# 5. 性能评估

| Model | NaiveRAG | | GraphRAG | | LightRAG | | **MiniRAG** | |
|-------|----------|----------|-----------|----------|-----------|----------|----------|----------|
| | acc↑ | err↓ | acc↑ | err↓ | acc↑ | err↓ | acc↑ | err↓ |
| LiHua-World | | | | | | | | |
| Phi-3.5-mini-instruct | 41.22% | 23.20% | / | / | 39.81% | 25.39% | **53.29%** | 23.35% |
| GLM-Edge-1.5B-Chat | 42.79% | 24.76% | / | / | 35.74% | 25.86% | **52.51%** | 25.71% |
| Qwen2.5-3B-Instruct | 43.73% | 24.14% | / | / | 39.18% | 28.68% | **48.75%** | 26.02% |
| MiniCPM3-4B | 43.42% | 17.08% | / | / | 35.42% | 21.94% | **51.25%** | 21.79% |
| gpt-4o-mini | 46.55% | 19.12% | 35.27% | 37.77% | **56.90%** | 20.85% | 54.08% | 19.44% |
| MultiHop-RAG | | | | | | | | |
| Phi-3.5-mini-instruct | 42.72% | 31.34% | / | / | 27.03% | 11.78% | **49.96%** | 28.44% |
| GLM-Edge-1.5B-Chat | 44.44% | 24.26% | / | / | / | / | **51.41%** | 23.44% |
| Qwen2.5-3B-Instruct | 39.48% | 31.69% | / | / | 21.91% | 13.73% | **48.55%** | 33.10% |
| MiniCPM3-4B | 39.24% | 31.42% | / | / | 19.48% | 10.41% | **47.77%** | 26.88% |
| gpt-4o-mini | 53.60% | 27.19% | 60.92% | 16.86% | 64.91% | 19.37% | **68.43%** | 19.41% |

表中，/ 表示该方法难以生成有效响应。

实验结果显示，当将大型语言模型(LLM)替换为小型语言模型(SLM)时，各框架表现差异显著：GraphRAG则因无法保证生成质量而完全失效，LightRAG的性能断崖式下降(最高降幅达45.43%)。

相比之下，MiniRAG展现出优秀的稳定性——性能降幅最大仅为21.26%，最小仅0.79%。更值得注意的是，MiniRAG仅使用了约1/4的存储空间，便实现了这一出色表现。